# Benchmarks

Performance benchmarks for claude-code-statusline engines.

**Latest results: [`RESULTS.md`](RESULTS.md)** — auto-generated by CI on every push to main.

## Quick start

```bash
make bench           # benchmark all available engines
make bench-bash      # benchmark bash only
make bench-python    # benchmark python only
make bench-go        # benchmark Go only
make bench-rust      # benchmark Rust only
make bench-report    # run benchmarks + generate RESULTS.md
make profile         # detailed bash subprocess profiling
```

## Prerequisites

```bash
brew install hyperfine   # macOS
# apt-get install hyperfine   # Ubuntu
```

## What we measure

### `bench.sh` — Engine comparison

Uses [hyperfine](https://github.com/sharkdp/hyperfine) to measure end-to-end render time for each engine against the same fixture (`tests/fixtures/basic-session.json`).

Two benchmark modes:
- **Render only** (`--no-git --no-cumulative`): pure JSON→ANSI speed
- **With git** (`--no-cumulative`): includes branch, dirty check, ahead/behind, stash

Parameters:
- **Warmup**: 5 runs (prime filesystem caches)
- **Min runs**: 50 (statistical significance)
- **Output**: JSON + Markdown in `results/`, plus `RESULTS.md` report in `--ci` mode

### `generate-report.sh` — Report generator

Takes hyperfine JSON output and produces `RESULTS.md` with:
- Render-only comparison table with inline bar charts
- With-git comparison table
- Git overhead analysis (delta between the two modes)
- Relative speed rankings
- Key takeaways

### `profile-bash.sh` — Subprocess profiling

Measures individual subprocess costs in the bash engine:

- Each `jq` call (~11 invocations per render)
- Each `git` call (~7 invocations per render)
- Each `bc` call (~4 invocations per render)
- Total subprocess overhead vs full render time

This reveals where bash spends time and why alternatives (Python with native JSON parsing, Go/Rust with no subprocesses) are faster.

## Methodology

1. All benchmarks use the same fixture file for fair comparison
2. Git operations run in the actual repo (so git calls are realistic)
3. Cumulative caches are NOT populated (tests worst-case for cache miss)
4. Background jobs (model parse, cost scan) are spawned but not awaited
5. Results include process startup time (important for Python vs compiled)

## CI integration

The `benchmark` job in `.github/workflows/ci.yml` runs on every push to main:
1. Builds all engines (Go + Rust)
2. Runs `bench.sh --ci` with hyperfine
3. Generates `RESULTS.md` via `generate-report.sh`
4. Auto-commits if results changed

CI hardware: GitHub Actions `ubuntu-latest` (2-core x86_64). Numbers differ from local machines but relative comparisons are consistent.

## Results directory

Raw hyperfine output is saved in `results/` with timestamps (gitignored, machine-specific). The committed `RESULTS.md` is the canonical reference.
